{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01f361ddc47e0b386595316fe3d7f4dabbd260db"
   },
   "source": [
    "**Notebook Objective:**\n",
    "\n",
    "Objective of the notebook is to look at the different pretrained embeddings provided in the dataset and to see how they are useful in the model building process. \n",
    "\n",
    "First let us import the necessary modules and read the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############CNN##############\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import keras \n",
    "from keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, CuDNNLSTM\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('../input/ai-data/data.tsv',delimiter='\\t', header=None)\n",
    "data.columns=['query_id','query','passage','label','passage_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90880e400731a2b742e89f333237bfda07957df8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../input/movie-title-analysis/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba5a1b8109dee2c9fbc628d5da4a7c3447d42fb8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_X, val_X, train_y, val_y= train_test_split(data.drop('Categories', axis=1), data['Categories'], test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "178a758e3fc6d2f79beb191813ac60d34f30cc97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Get Glove embeddings in a dictionary with every word as key and its embeddings as its values\n",
    "glove_embeddings={}\n",
    "file=open(\"../input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt\")\n",
    "for line in file:\n",
    "    tokens= line.split(\" \")\n",
    "    word = tokens[0]\n",
    "    vec = tokens[1:]\n",
    "    glove_embeddings[word]=np.asarray(vec, dtype='float32')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d63342b60e52acef14131cf382689f5007c1743d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######Movie Overview Analysis\n",
    "##Convert text to sequences\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 10000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 30 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_X[\"overview\"].fillna(\"_na_\").values\n",
    "\n",
    "\n",
    "val_X = val_X[\"overview\"].fillna(\"_na_\").values\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "\n",
    "embedding_matrix = np.zeros((max_features, embed_size))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae67f907fedebd5b3d6993d02eb555654f0c74e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del glove_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3b3c2061037961c70a2e3f0020dfafba4086d47",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dddf72957caf41b69d221e565d7a67be9cfb7dde",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1=keras.layers.Input(shape=(maxlen_ques,), dtype='float32')\n",
    "x=keras.layers.Embedding(input_dim=max_features_ques,output_dim=embed_size, weights=[embedding_matrix_ques], trainable=False)(inp1)\n",
    "x=keras.layers.Bidirectional(CuDNNLSTM(64,return_sequences=True))(x)\n",
    "x=keras.layers.Bidirectional(CuDNNLSTM(32, return_sequences=True))(x)\n",
    "x=keras.layers.GlobalMaxPool1D()(x)\n",
    "x=Dropout(0.1)(x)\n",
    "x=keras.layers.Dense(64 ,activation='relu')(x)\n",
    "\n",
    "inp2=keras.layers.Input(shape=(maxlen_sent,), dtype='float32')\n",
    "y=keras.layers.Embedding(input_dim=max_features_sent,output_dim=embed_size, weights=[embedding_matrix_sent],trainable=False)(inp2)\n",
    "y=keras.layers.Bidirectional(CuDNNLSTM(64,return_sequences=True))(y)\n",
    "y=keras.layers.Bidirectional(CuDNNLSTM(32, return_sequences=True))(y)\n",
    "y=keras.layers.GlobalMaxPool1D()(y)\n",
    "y=Dropout(0.1)(y)\n",
    "y=keras.layers.Dense(64 ,activation='relu')(y)\n",
    "\n",
    "merge=keras.layers.multiply([x,y])\n",
    "dense=keras.layers.Dense(32,activation='relu')(merge)\n",
    "out=Dense(2, activation='softmax')(dense)\n",
    "model=Model(inputs=[inp1, inp2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "284781b8279757eb905490a5aca2b9b4a46bb953",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1=keras.layers.Input(shape=(maxlen,), dtype='float32')\n",
    "x=keras.layers.Embedding(input_dim=max_features,output_dim=embed_size, weights=[embedding_matrix])(inp1)\n",
    "x=keras.layers.Bidirectional(CuDNNLSTM(64,return_sequences=True))(x)\n",
    "x=keras.layers.Bidirectional(CuDNNLSTM(32))(x)\n",
    "#x=keras.layers.GlobalMaxPool1D()(x)\n",
    "#x=Dropout(0.1)(x)\n",
    "x=keras.layers.Dense(64 ,activation='relu')(x)\n",
    "out=Dense(4, activation='softmax')(x)\n",
    "model=Model(inputs=inp1, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33cbe1f445444fdfb5f580da714cce67250dd4f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db4b245e5f83a8ed9bb9a7902ed13b2bc10162c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=train_X, y=pd.get_dummies(train_y),batch_size=32,epochs=100 ,\n",
    "         validation_data=(val_X,pd.get_dummies(val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "791242cbd59944245040fe04994a9a54f7974f9e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict([val_X_ques,val_X_sent], batch_size=512, verbose=1)[:,1]\n",
    "test_data1 = val.loc[:,['query_id','label']]\n",
    "test_data1.loc[:,'pred'] = pred\n",
    "test_data1.loc[:,'rank1'] = test_data1.groupby('query_id')['pred'].rank(ascending=False)\n",
    "eval_data = test_data1.loc[test_data1.label == 1, :]\n",
    "eval_data.loc[:,'score'] = eval_data['rank1'].apply(lambda x : 1/x)\n",
    "eval_data.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54598aa4457940d26dcf07ed9d57a4146a1b6672",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad5757a076aa88240e51b5633db6d0315533dfb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train['label'].values\n",
    "val_y = val['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d6709d6440495853001991c9b140c14bd18bb03",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect=TfidfVectorizer(stop_words='english',max_df=0.9, min_df=2)\n",
    "tfidf_train=tfidf_vect.fit_transform(train['passage'])\n",
    "tfidf_val=tfidf_vect.transform(val['passage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37cf544c767c09f49a38cc3a1331d3375e2cde67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm1=lgbm.LGBMClassifier(silent=False, max_depth=5,n_estimators=1000)\n",
    "lgbm1.fit(tfidf_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b7423b350cdd225b371d7610303ddc85268b142",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=lgbm1.predict_proba(tfidf_val)[:,1]\n",
    "test_data1 = val.loc[:,['query_id','label']]\n",
    "test_data1.loc[:,'pred'] = pred\n",
    "test_data1.loc[:,'rank1'] = test_data1.groupby('query_id')['pred'].rank(ascending=False)\n",
    "eval_data = test_data1.loc[test_data1.label == 1, :]\n",
    "eval_data.loc[:,'score'] = eval_data['rank1'].apply(lambda x : 1/x)\n",
    "eval_data.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09f716a5ffff3d101141c710da085a9b5a0923b1",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f42c1bbd8ed0daf358d2cb613f1f47adf09b675",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcaff522a1fe0da65c52a46651487495d00c0067",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4634b68562952738629b607c67bd7ef7f26aad77",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7bdc3669dd614d80e30303e051613a370f9f817",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d7feb6bdfced9613cde9ae16687dd2c54804e80",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2425036edd7f4b77a9036bf20a45c37a41100007",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5aaf4201c2a9084eac208c9954d9782369246f5",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
